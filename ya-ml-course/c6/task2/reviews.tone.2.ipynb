{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.pipeline import Pipeline\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "negfeats = [movie_reviews.words(fileids=[f]) for f in negids]\n",
    "posfeats = [movie_reviews.words(fileids=[f]) for f in posids]\n",
    "\n",
    "data = []\n",
    "for words in negfeats:\n",
    "    data.append(dict(\n",
    "        text=' '.join(words),\n",
    "        positive=0,\n",
    "    ))\n",
    "\n",
    "for words in posfeats:\n",
    "    data.append(dict(\n",
    "        text=' '.join(words),\n",
    "        positive=1,\n",
    "    ))\n",
    "\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classificator', LogisticRegression()),\n",
    "])\n",
    "\n",
    "cv_pipeline_svc = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classificator', LinearSVC()),\n",
    "])\n",
    "\n",
    "cv_pipeline_sgd = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classificator', SGDClassifier(\n",
    "        loss='hinge', penalty='l2',\n",
    "        alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=5,\n",
    "        shuffle=True, verbose=0, epsilon=0.1, n_jobs=1, random_state=42,\n",
    "        learning_rate='optimal', eta0=0.0, power_t=0.5, class_weight=None,\n",
    "        warm_start=False, average=False\n",
    "    )),\n",
    "])\n",
    "\n",
    "cv_pipeline10 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(min_df=10)),\n",
    "    ('classificator', LogisticRegression()),\n",
    "])\n",
    "\n",
    "cv_pipeline50 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(min_df=50)),\n",
    "    ('classificator', LogisticRegression()),\n",
    "])\n",
    "\n",
    "tf_pipeline_log = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classificator', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.805 , 0.845 , 0.84  , 0.8725, 0.85  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result = cross_val_score(cv_pipeline, data.text, data.positive, cv=5)\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82  , 0.825 , 0.825 , 0.815 , 0.8175])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_log_result = cross_val_score(tf_pipeline_log, data.text, data.positive, cv=5)\n",
    "tf_log_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.815 , 0.8525, 0.835 , 0.855 , 0.84  ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv10_result = cross_val_score(cv_pipeline10, data.text, data.positive, cv=5)\n",
    "cv10_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7875, 0.825 , 0.8125, 0.82  , 0.8225])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv50_result = cross_val_score(cv_pipeline50, data.text, data.positive, cv=5)\n",
    "cv50_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8025, 0.84  , 0.83  , 0.85  , 0.84  ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_svc_result = cross_val_score(cv_pipeline_svc, data.text, data.positive, cv=5)\n",
    "cv_svc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7175, 0.8075, 0.8375, 0.725 , 0.83  ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_sgd_result = cross_val_score(cv_pipeline_sgd, data.text, data.positive, cv=5)\n",
    "cv_sgd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82  , 0.85  , 0.835 , 0.8475, 0.8475])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_nltk_result = cross_val_score(\n",
    "    Pipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words=stopwords.words('english'))),\n",
    "        ('estimator', LogisticRegression())\n",
    "    ]),\n",
    "    data.text, data.positive, cv=5,\n",
    ")\n",
    "stop_words_nltk_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81  , 0.84  , 0.8425, 0.8475, 0.8425])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_default_result = cross_val_score(\n",
    "    Pipeline([\n",
    "        ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "        ('estimator', LogisticRegression())\n",
    "    ]),\n",
    "    data.text, data.positive, cv=5,\n",
    ")\n",
    "stop_words_default_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82  , 0.8575, 0.845 , 0.865 , 0.885 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_word_result = cross_val_score(\n",
    "    Pipeline([\n",
    "        ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "        ('estimator', LogisticRegression())\n",
    "    ]),\n",
    "    data.text, data.positive, cv=5,\n",
    ")\n",
    "ngram_word_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8175, 0.84  , 0.8225, 0.8275, 0.8175])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_letter_result = cross_val_score(\n",
    "    Pipeline([\n",
    "        ('vectorizer', CountVectorizer(ngram_range=(3, 5), analyzer='char_wb')),\n",
    "        ('estimator', LogisticRegression())\n",
    "    ]),\n",
    "    data.text, data.positive, cv=5,\n",
    ")\n",
    "ngram_letter_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ans1.txt', 'w') as fp:\n",
    "    fp.write(\n",
    "        f'{round(np.mean(cv_result), 4)} '\n",
    "        f'{round(np.std(cv_result), 4)} '\n",
    "        f'{round(np.mean(tf_log_result), 4)} '\n",
    "        f'{round(np.std(tf_log_result), 4)}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ans2.txt', 'w') as fp:\n",
    "    fp.write(\n",
    "        f'{round(np.mean(cv10_result), 4)} '\n",
    "        f'{round(np.mean(cv50_result), 4)}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgd', 0.7835), ('svc', 0.8325000000000001), ('log', 0.8424999999999999)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_results = [\n",
    "    ('log', np.mean(cv_result)),\n",
    "    ('svc', np.mean(cv_svc_result)),\n",
    "    ('sgd', np.mean(cv_sgd_result)),\n",
    "]\n",
    "classifier_results.sort(key=itemgetter(1))\n",
    "classifier_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ans3.txt', 'w') as fp:\n",
    "    fp.write(str(classifier_results[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ans4.txt', 'w') as fp:\n",
    "    fp.write(\n",
    "        f'{round(np.mean(stop_words_nltk_result), 4)} '\n",
    "        f'{round(np.mean(stop_words_default_result), 4)}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ans5.txt', 'w') as fp:\n",
    "    fp.write(\n",
    "        f'{round(np.mean(ngram_word_result), 4)} '\n",
    "        f'{round(np.mean(ngram_letter_result), 4)}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a0ca82fe72f7b6dcc59f88ce1601f3112cb58c024b4d57901a90c4fbc3fa1c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
