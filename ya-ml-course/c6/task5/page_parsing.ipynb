{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заголовки верхнего уровня\n",
    "\n",
    "https://en.wikipedia.org/wiki/Bias-variance_tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_text(result_set):\n",
    "    if len(result_set):\n",
    "        item = result_set\n",
    "        if not getattr(item, 'find_all', None):\n",
    "            item = result_set[0]\n",
    "        texsts = item.find_all(string=True)\n",
    "        return ' '.join(texsts).strip()\n",
    "    return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents\n",
      "Motivation [ edit ]\n",
      "Bias–variance decomposition of mean squared error [ edit ]\n",
      "Approaches [ edit ]\n",
      "Applications [ edit ]\n",
      "See also [ edit ]\n",
      "References [ edit ]\n",
      "Navigation menu\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get('https://en.wikipedia.org/wiki/Bias-variance_tradeoff')\n",
    "resp.raise_for_status()\n",
    "\n",
    "bs = bs4.BeautifulSoup(resp.text, 'lxml')\n",
    "headers = bs.select('h2')\n",
    "\n",
    "for header in headers:\n",
    "    print(get_node_text(header))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Названия статей\n",
    "\n",
    "https://en.wikipedia.org/wiki/Category:Machine_learning_algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adagrad\n",
      "Algorithms of Oppression\n",
      "Almeida–Pineda recurrent backpropagation\n",
      "Augmented Analytics\n",
      "Backpropagation\n",
      "Bioz\n",
      "Bootstrap aggregating\n",
      "CN2 algorithm\n",
      "Constructing skill trees\n",
      "Deep reinforcement learning\n",
      "Dehaene–Changeux model\n",
      "Diffusion map\n",
      "Dominance-based rough set approach\n",
      "Dynamic time warping\n",
      "Elastic net regularization\n",
      "Error-driven learning\n",
      "Evolutionary multimodal optimization\n",
      "Expectation–maximization algorithm\n",
      "Extremal Ensemble Learning\n",
      "FastICA\n",
      "Federated Learning of Cohorts\n",
      "Forward–backward algorithm\n",
      "GeneRec\n",
      "Genetic Algorithm for Rule Set Production\n",
      "Growing self-organizing map\n",
      "Hyper basis function network\n",
      "IDistance\n",
      "Incremental learning\n",
      "K-nearest neighbors algorithm\n",
      "Kernel methods for vector output\n",
      "Kernel principal component analysis\n",
      "Label propagation algorithm\n",
      "Lasso (statistics)\n",
      "Leabra\n",
      "Linde–Buzo–Gray algorithm\n",
      "Local outlier factor\n",
      "Logic learning machine\n",
      "LogitBoost\n",
      "Loss functions for classification\n",
      "Manifold alignment\n",
      "Minimum redundancy feature selection\n",
      "Mixture of experts\n",
      "Multiple kernel learning\n",
      "NarxCare\n",
      "Non-negative matrix factorization\n",
      "Online machine learning\n",
      "Out-of-bag error\n",
      "Prefrontal cortex basal ganglia working memory\n",
      "Prototype methods\n",
      "PVLV\n",
      "Q-learning\n",
      "Quadratic unconstrained binary optimization\n",
      "Query-level feature\n",
      "Quickprop\n",
      "Radial basis function network\n",
      "Randomized weighted majority algorithm\n",
      "Repeated incremental pruning to produce error reduction (RIPPER)\n",
      "Rprop\n",
      "Rule-based machine learning\n",
      "Skill chaining\n",
      "Sparse PCA\n",
      "State–action–reward–state–action\n",
      "Stochastic gradient descent\n",
      "Structured kNN\n",
      "T-distributed stochastic neighbor embedding\n",
      "Triplet loss\n",
      "Wake-sleep algorithm\n",
      "Weighted majority algorithm (machine learning)\n",
      "Zero-shot learning\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get('https://en.wikipedia.org/wiki/Category:Machine_learning_algorithms')\n",
    "resp.raise_for_status()\n",
    "\n",
    "bs = bs4.BeautifulSoup(resp.text, 'lxml')\n",
    "names = bs.select('.mw-category-group a')\n",
    "\n",
    "for name in names:\n",
    "    print(get_node_text(name))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a0ca82fe72f7b6dcc59f88ce1601f3112cb58c024b4d57901a90c4fbc3fa1c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
